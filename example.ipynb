{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabM\n",
    "\n",
    "This is a standalone usage example for the TabM project.\n",
    "The easiest way to run it is [Pixi](https://pixi.sh/latest/#installation):\n",
    "\n",
    "```shell\n",
    "git clone https://github.com/yandex-research/tabm\n",
    "cd tabm\n",
    "\n",
    "# With GPU:\n",
    "pixi run -e cuda jupyter-lab example.ipynb\n",
    "\n",
    "# Without GPU:\n",
    "pixi run jupyter-lab example.ipynb\n",
    "```\n",
    "\n",
    "For the full overview of the project, and for non-Pixi environment setups, see README in the repository:\n",
    "https://github.com/yandex-research/tabm\n",
    "\n",
    "This notebook is based on the original example: https://github.com/yandex-research/tabm/blob/main/example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/yandex-research/tabm\n",
    "!pip install wldhx.yadisk-direct rtdl_num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rtdl_num_embeddings  # https://github.com/yandex-research/rtdl-num-embeddings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, OrdinalEncoder\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "# uncomment the following import if working in colab and comment the next one\n",
    "# from tabm.tabm_reference import Model, make_parameter_groups\n",
    "from tabm_reference import Model, make_parameter_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed + 1)\n",
    "torch.manual_seed(seed + 2)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Automatic mixed precision (AMP)\n",
    "# torch.float16 is implemented for completeness,\n",
    "# but it was not tested in the project,\n",
    "# so torch.bfloat16 is used by default.\n",
    "amp_dtype = (\n",
    "    torch.bfloat16\n",
    "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "    else torch.float16\n",
    "    if torch.cuda.is_available()\n",
    "    else None\n",
    ")\n",
    "# Changing False to True will result in faster training on compatible hardware.\n",
    "amp_enabled = False and amp_dtype is not None\n",
    "grad_scaler = torch.cuda.amp.GradScaler() if amp_dtype is torch.float16 else None  # type: ignore\n",
    "\n",
    "# torch.compile\n",
    "compile_model = False\n",
    "\n",
    "# fmt: off\n",
    "print(\n",
    "    f'Device:        {device.type.upper()}'\n",
    "    f'\\nAMP:           {amp_enabled} (dtype: {amp_dtype})'\n",
    "    f'\\ntorch.compile: {compile_model}'\n",
    ")\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Dataset is \"Regression with an Insurance Dataset\"\n",
    "\n",
    "https://www.kaggle.com/competitions/playground-series-s4e12/overview\n",
    "\n",
    "if you have a kaggle account, you can download the data using kaggle API:\n",
    "\n",
    "```python\n",
    "kaggle competitions download -c playground-series-s4e12\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -L $(yadisk-direct https://disk.yandex.ru/d/YbkU_KfAqGtdXg) -o insurance_dataset_train.csv\n",
    "! curl -L $(yadisk-direct https://disk.yandex.ru/d/_gs3p3yvp0TNRg) -o insurance_dataset_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload train and test parts\n",
    "train_df = pd.read_csv(\"./insurance_dataset_train.csv\")\n",
    "test_df = pd.read_csv(\"./insurance_dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define lists with numerical and categorical column names.\n",
    "\n",
    "Also we exclude `id` and `Policy Start Date` cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"Premium Amount\"\n",
    "\n",
    "num_cols = ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', \n",
    "            'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "cat_cols = ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location',\n",
    "            'Policy Type', 'Customer Feedback', 'Smoking Status', 'Exercise Frequency',\n",
    "            'Property Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train part on train and val, test parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If training is TOO slow, set to True\n",
    "DEMO_MODE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect number of unique values for categorical columns. Will be needed in future.\n",
    "cat_cardinalities = train_df[cat_cols].nunique(dropna=False).to_list()\n",
    "\n",
    "if DEMO_MODE:\n",
    "    idx = np.random.randint(0, len(train_df), size=50000)\n",
    "    train_df = train_df.iloc[idx]\n",
    "\n",
    "all_idx = np.arange(len(train_df))\n",
    "# Select the test part\n",
    "train_idx, val_idx = train_test_split(all_idx, train_size=0.8)\n",
    "\n",
    "# Fill dict with all parts we have\n",
    "_train_df = train_df.iloc[train_idx]\n",
    "_val_df = train_df.iloc[val_idx]\n",
    "\n",
    "data = {\n",
    "    'train': {\n",
    "        'x_num': _train_df[num_cols],\n",
    "        'x_cat': _train_df[cat_cols],\n",
    "        'y': _train_df[target_col].to_numpy().astype(np.float32)\n",
    "    },\n",
    "    'val': {\n",
    "        'x_num': _val_df[num_cols],\n",
    "        'x_cat': _val_df[cat_cols],\n",
    "        'y': _val_df[target_col].to_numpy().astype(np.float32)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Also process test data, we'll need it in the end\n",
    "test_data = {\n",
    "    \"x_num\": test_df[num_cols],\n",
    "    \"x_cat\": test_df[cat_cols],\n",
    "    'id': test_df['id'].to_numpy()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define processing pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_quantiles = max(min(len(train_idx) // 30, 1000), 10)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", QuantileTransformer(n_quantiles=n_quantiles, \n",
    "                                   output_distribution='normal',\n",
    "                                   subsample=10**9))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply processing operations to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The noise is added to improve the output of QuantileTransformer in some cases\n",
    "noise = (\n",
    "    np.random.default_rng(0)\n",
    "    .normal(0.0, 1e-5, data['train']['x_num'].shape)\n",
    ")\n",
    "\n",
    "# Fit pipelines on train part\n",
    "num_processor = num_pipeline.fit(data['train']['x_num'] + noise)\n",
    "cat_processor = cat_pipeline.fit(data['train']['x_cat'])\n",
    "\n",
    "# Apply the processing to all parts. Note, that when processor is applied\n",
    "# each dataframe converts to np.ndarray. Check that x_num array has float32 dtype\n",
    "# and x_cat is int64.\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "print(f\"`x_num` dtype: {type(data['train']['x_num'])}\\n`x_cat` dtype: {type(data['train']['x_cat'])}\")\n",
    "\n",
    "# Apply processing to test data as well\n",
    "\n",
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert every part of the dataset to `torch.tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "data_torch = {\n",
    "    part: {k: torch.as_tensor(v, device=device) for k, v in data[part].items()}\n",
    "    for part in data\n",
    "}\n",
    "\n",
    "test_data_torch = {\n",
    "    \"x_num\": torch.as_tensor(test_data[\"x_num\"], device=device),\n",
    "    \"x_cat\": torch.as_tensor(test_data[\"x_cat\"], device=device)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one of the two configurations below.\n",
    "\n",
    "# TabM or TabM-mini\n",
    "# arch_type = 'tabm'\n",
    "arch_type = 'tabm-mini'\n",
    "\n",
    "# Use the piecewise-linear embeddings\n",
    "bins = rtdl_num_embeddings.compute_bins(data_torch['train']['x_num'])\n",
    "# bins = None\n",
    "\n",
    "model = Model(\n",
    "    n_num_features=len(num_cols),\n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    n_classes=None,\n",
    "    backbone={\n",
    "        'type': 'MLP',\n",
    "        'n_blocks': 3 if bins is None else 2,\n",
    "        'd_block': 512,\n",
    "        'dropout': 0.1,\n",
    "    },\n",
    "    bins=bins,\n",
    "    num_embeddings=(\n",
    "        None\n",
    "        if bins is None\n",
    "        else {\n",
    "            'type': 'PiecewiseLinearEmbeddings',\n",
    "            'd_embedding': 16,\n",
    "            'activation': False,\n",
    "            'version': 'B',\n",
    "        }\n",
    "    ),\n",
    "    arch_type=arch_type,\n",
    "    k=32,\n",
    ").to(device)\n",
    "\n",
    "if compile_model:\n",
    "    # NOTE\n",
    "    # `torch.compile` is intentionally called without the `mode` argument\n",
    "    # (mode=\"reduce-overhead\" caused issues during training with torch==2.0.1).\n",
    "    model = torch.compile(model)\n",
    "    evaluation_mode = torch.no_grad\n",
    "else:\n",
    "    evaluation_mode = torch.inference_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of params: \", sum(p.numel() for p in model.parameters()))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Loss in kaggle competition is RMSLE (Root Mean Squared Logarithmic Error) let's use it as validation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "def compute_rmsle(y_pred, y_true):\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "    y_true = y_true.detach().cpu().numpy()\n",
    "    return root_mean_squared_log_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define class for training and evaluating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner:\n",
    "    \"\"\"Runner for train/evaludate and predict using provided model.\"\"\"\n",
    "    def __init__(self, model, optimizer, loss, device, eval_metric=None, grad_scaler=None, \n",
    "                 epoch_bar=False, checkpoint_name=\"tabm_model.ckpt\"):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.device = device\n",
    "        self.eval_metric = loss if eval_metric is None else eval_metric\n",
    "        self.grad_scaler = grad_scaler\n",
    "        self.epoch_bar = epoch_bar\n",
    "        self.checkpoint_name = checkpoint_name\n",
    "\n",
    "        self._train_mean = None\n",
    "        self._train_std = None\n",
    "\n",
    "    def compute_loss(self, y_pred, y_true):\n",
    "        # TabM produces k predictions per object. Each of them must be trained separately.\n",
    "        # (regression)     y_pred.shape == (batch_size, k)\n",
    "        k = y_pred.shape[-1]\n",
    "        return self.loss(y_pred.flatten(0, 1), y_true.repeat_interleave(k))\n",
    "\n",
    "    def forward(self, batch_num, batch_cat=None, model=None):\n",
    "        model = self.model if model is None else model\n",
    "        return (\n",
    "            model(batch_num, batch_cat)\n",
    "            .squeeze(-1)\n",
    "            .float()\n",
    "        )\n",
    "\n",
    "    def _train_step(self, y_pred, y_true, normalize_target):\n",
    "        # We need to normalize target if needed and compute loss\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        if self.grad_scaler is None:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        else:\n",
    "            self.grad_scaler.scale(loss).backward()\n",
    "            self.grad_scaler.step(optimizer)\n",
    "            self.grad_scaler.update()\n",
    "        self.optimizer.zero_grad()\n",
    "        return loss.detach().cpu().numpy().mean()\n",
    "    \n",
    "    def _eval_step(self, y_pred, y_true):\n",
    "        # Compute the mean of the k predictions and scale prediction \n",
    "        # into it's original range\n",
    "\n",
    "        y_pred = ### YOUR CODE HERE\n",
    "\n",
    "        # Avoid computing gradients if train_phase is False\n",
    "        with torch.set_grad_enabled(False):\n",
    "            metric = self.eval_metric(y_pred, y_true)\n",
    "        if isinstance(metric, torch.Tensor):\n",
    "            return metric.detach().cpu().numpy()\n",
    "        return metric\n",
    "\n",
    "    def _run_epoch(self, data, batch_indices, train_phase=True, normalize_target=True, model=None):\n",
    "        self.model.train(train_phase)\n",
    "        epoch_history = []\n",
    "        for batch_idx in tqdm(batch_indices, disable=not self.epoch_bar, leave=False):\n",
    "            batch_num = data['x_num'][batch_idx]\n",
    "            batch_cat = data['x_cat'][batch_idx]\n",
    "            y_true = data['y'][batch_idx]\n",
    "            y_pred = self.forward(batch_num, batch_cat, model=model)\n",
    "\n",
    "            if train_phase:\n",
    "                res = self._train_step(y_pred, y_true, normalize_target=normalize_target)\n",
    "            else:\n",
    "                res = self._eval_step(y_pred, y_true)\n",
    "            epoch_history.append(res)\n",
    "        return np.mean(epoch_history)\n",
    "\n",
    "    def train(self, train_data, val_data, batch_size=256, n_epochs=1000, patience=16,\n",
    "              eval_batch_size=None, normalize_target=True, save_best_model=False, \n",
    "              force_collect_stats=False):\n",
    "        best = {\n",
    "            'val': math.inf,\n",
    "            'test': math.inf,\n",
    "            'epoch': -1,\n",
    "        }\n",
    "\n",
    "        # Important!\n",
    "        # For regression tasks it is highly recommended to standardize the training labels.\n",
    "        self._train_mean = (train_data['y'].mean() \n",
    "                            if self._train_mean is None or force_collect_stats \n",
    "                            else self._train_mean)\n",
    "        self._train_std = (train_data['y'].std() \n",
    "                           if self._train_std is None or force_collect_stats \n",
    "                           else self._train_std)\n",
    "\n",
    "        # Early stopping: the training stops when\n",
    "        # there are more than `patience` consequtive bad updates.\n",
    "        remaining_patience = patience\n",
    "        eval_batch_size = batch_size if eval_batch_size is None else eval_batch_size\n",
    "        for epoch in tqdm(range(n_epochs), total=n_epochs):\n",
    "            # Generate batch indices\n",
    "            batch_indices = torch.randperm(len(train_data['y']), device=device).split(batch_size)\n",
    "            # Perform train epoch\n",
    "            train_score = self._run_epoch(train_data, batch_indices, train_phase=True,\n",
    "                                          normalize_target=normalize_target)\n",
    "            # Validate model after train epoch\n",
    "            val_score = self.evaluate(val_data, eval_batch_size)\n",
    "\n",
    "            msg = f\"Epoch: {epoch} (train) {train_score:.4f} (val) {val_score:.4f}\"\n",
    "        \n",
    "            if val_score < best['val']:\n",
    "                best = {'val': val_score, 'epoch': epoch}\n",
    "                remaining_patience = patience\n",
    "                print(msg + \"\\t🌸 New best epoch! 🌸\")\n",
    "                if save_best_model:\n",
    "                    torch.save(self.model, open(self.checkpoint_name, 'wb'))\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "                print(msg)\n",
    "        \n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "        print(f\"\\nTraining is complete.\\nBest model: epoch {best['epoch']} metric {best['val']}\")\n",
    "\n",
    "    @evaluation_mode\n",
    "    def evaluate(self, data, batch_size=256, model=None):\n",
    "        batch_indices = torch.randperm(len(data['y']), device=device).split(batch_size)\n",
    "        return self._run_epoch(data, batch_indices, train_phase=False, model=model)\n",
    "\n",
    "    @evaluation_mode\n",
    "    def predict(self, data, batch_size=256, model=None):\n",
    "        batch_indices = torch.arange(len(data['x_num']), device=device).split(batch_size)\n",
    "        preds = []\n",
    "        for batch_idx in tqdm(batch_indices, disable=not self.epoch_bar, leave=False):\n",
    "            batch_num = data['x_num'][batch_idx]\n",
    "            batch_cat = data['x_cat'][batch_idx]\n",
    "            # You need to make prediction for batch and store result in `preds`\n",
    "            # Don't forget to scale prediction into it's orginal range\n",
    "            y_pred = ### YOUR CODE HERE\n",
    "\n",
    "            preds.extend(y_pred.detach().cpu().numpy())\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create runner instance and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(make_parameter_groups(model), lr=2e-3, weight_decay=3e-4)\n",
    "loss = F.mse_loss\n",
    "eval_metric = compute_rmsle\n",
    "\n",
    "runner = Runner(model, optimizer, loss, device=device, eval_metric=eval_metric,\n",
    "                grad_scaler=grad_scaler, epoch_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train(data_torch['train'], data_torch['val'], batch_size=1024, n_epochs=15, save_best_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to improve the result??\n",
    "* Play with network params\n",
    "* Try to use or dont use embeddings\n",
    "* Try different models (tabM, tabM_mini)\n",
    "* (*) Tune model params using optuna ([source](https://optuna.org/), [examples](https://github.com/optuna/optuna-examples))\n",
    "* Any other ideas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about standard approaches? Let's try catboost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using colab\n",
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "kwargs = {\"task_type\": 'GPU', \"devices\": \"0\"} if torch.cuda.is_available() else {}\n",
    "catboost_model = CatBoostRegressor(**kwargs, iterations=500)\n",
    "\n",
    "X_cb = train_df[cat_cols + num_cols].fillna(0)\n",
    "y_cb = train_df[target_col]\n",
    "catboost_model.fit(X_cb, y_cb, cat_features=cat_cols, verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_preds = catboost_model.predict(test_df[cat_cols + num_cols].fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission\n",
    "\n",
    "Tips:\n",
    "* Save your local \"best\" results, to prevent overfitting on validation part\n",
    "* (simple) Before making submission (after params tuning), train model using whole train part (insurance_dataset_train)\n",
    "* (harder) Make submission as an ensemble of cross-validated models on the train part of the dataset\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(preds, ids, path=None):\n",
    "    result = pd.DataFrame({\"id\": ids, \"Premium Amount\": preds})\n",
    "    if path is None:\n",
    "        return result\n",
    "    result.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model from checkpoint\n",
    "# with open(\"tabm_model.ckpt\", 'rb') as f:\n",
    "#     best_model = torch.load(f)\n",
    "# preds = runner.predict(test_data_torch, batch_size=2048, model=best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use model from last epoch\n",
    "preds = runner.predict(test_data_torch, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(preds, test_data[\"id\"], \"simple_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(catboost_preds, test_df[\"id\"], \"simple_catboost_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit using API\n",
    "\n",
    "You can submit your solution directly from colab!\n",
    "\n",
    "\n",
    "```python\n",
    "kaggle competitions submit -c playground-series-s4e12 -f submission.csv -m \"Message\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
